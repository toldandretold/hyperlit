<h1>What data sovereignty would mean for <em>The Docuverse</em></h1>
<p>If the author of any text had the full rights over access to the text, full access to the rights and permissions of their own data, what would this mean for content moderation?</p>
<p>It would mean that only the individual user could permanently &quot;ban&quot; access to their content. </p>
<p>Only they could change the access permissions of each row of data in their own data columns. </p>
<p>However, users could themselves opt in to sorting algorithms that, for example, didn't show downvoted data, or data which had been noted as opposing certain ethical standards that they chose to filter their journey through <em>The Docuverse</em>.</p>
<p>To make this more clear, take the example of an open access, and open source, academic article which has been shared to <em>The Docuverse</em>. Only the Author of that article has the ability to remove it from The Docuverse. However, anyone has the ability to <mark class='user-name_1738122293964' id='user-name_1738122293964' data-listener-attached='true'>comment</mark>, on any portion of that article. Only the authors of those in-text comments (or highlights) has the power to remove access to them. This presents a problem to the author of the academic article. What if -- for example -- a Nazi propagandist left extremely hateful comments, with links to excitations of mass violence against ethnic, sexual and gender minorities, and their communist &quot;sympathisers&quot;. No academic would want their article to serve as a platform for such hate. However, they -- as well as <em>The Docuverse</em> itself as a collective -- do have power over the publication settings of their article. As such, they can choose the settings which filter out the potential deluges of in-text comments. Likewise, users can themselves customise the way that in-text comments are filtered. After all, this is a necessary task, with or without Nazi propagandists. The result of this is that which Musk's X, doesn't allow. It allows nazi propaganda, but does not allow users to chose to filter out all Nazi propaganda, or porn.</p>
<p>In this strategic imaginary, those most exploited by global monopoly capital, or imperialism, would not be attacked in the global commons of knowledge. Where they were, would be in dark back channels which would never be officially censored, but would nevertheless be radically disempowered by peoples autonomous, decentralised, decision making. This would show that, rather than being a risk of data sovereignty, the entire crisis of content moderation would be largely <em>resolved</em> by it. </p>